{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/josha106/Dacon-First-Medical-AI-Contest/blob/main/%EC%A0%9C1%ED%9A%8C_Medical_AI_(MAI)_%EA%B2%BD%EC%A7%84%EB%8C%80%ED%9A%8C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3H1U6eEnfwv",
        "outputId": "7dfe2e47-00b7-4994-9ffa-4b0e6f2b25a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.18 (you have 1.4.15). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "import glob\n",
        "import cv2\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations.pytorch.transforms import ToTensorV2\n",
        "import torchvision.models as models\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uaPhKS1Qnvld"
      },
      "outputs": [],
      "source": [
        "CFG = {\n",
        "    'IMG_SIZE':224,\n",
        "    'EPOCHS':20,\n",
        "    'LEARNING_RATE':3e-4,\n",
        "    'BATCH_SIZE':32,\n",
        "    'SEED':41\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQ5VAkyFny3N"
      },
      "outputs": [],
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "seed_everything(CFG['SEED']) # Seed 고정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4VQrt5moj00",
        "outputId": "2c049e46-087a-4ea3-ca7f-1f5a5d94b0fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "samyz27GNPim"
      },
      "outputs": [],
      "source": [
        "def transform_path(df):\n",
        "  updated_paths = []\n",
        "  df = df\n",
        "\n",
        "  for path in df['path'].values:\n",
        "      new_path = path.replace('./train/', '/content/drive/MyDrive/open/train/')\n",
        "      updated_paths.append(new_path)\n",
        "\n",
        "  return updated_paths\n",
        "\n",
        "def transform_test_path(df):\n",
        "  updated_paths = []\n",
        "  df = df\n",
        "\n",
        "  for path in df['path'].values:\n",
        "      new_path = path.replace('./test/', '/content/drive/MyDrive/open/test/')\n",
        "      updated_paths.append(new_path)\n",
        "\n",
        "  return updated_paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E5kajO6-n4YU"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/open/train.csv')\n",
        "updated_paths = transform_path(df)\n",
        "df['path'] = updated_paths\n",
        "\n",
        "# train(80%) / valid(20%)\n",
        "train_len = int(len(df) * 0.8)\n",
        "train_df = df.iloc[:train_len]\n",
        "val_df = df.iloc[train_len:]\n",
        "\n",
        "# 2차원 벡터화\n",
        "train_label_vec = train_df.iloc[:,2:].values.astype(np.float32)\n",
        "val_label_vec = val_df.iloc[:,2:].values.astype(np.float32)\n",
        "\n",
        "CFG['label_size'] = train_label_vec.shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mxqVkmKdn6ap"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, img_path_list, label_list, transforms=None):\n",
        "        self.img_path_list = img_path_list\n",
        "        self.label_list = label_list\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_path = self.img_path_list[index]\n",
        "        image = cv2.imread(img_path)\n",
        "\n",
        "        # image A.compose로 규격 맞추기\n",
        "        if self.transforms is not None:\n",
        "            image = self.transforms(image=image)['image']\n",
        "\n",
        "        if self.label_list is not None:\n",
        "            label = self.label_list[index]\n",
        "            return image, label\n",
        "        else:\n",
        "            return image\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_path_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d_PVKKcvL5WG"
      },
      "outputs": [],
      "source": [
        "A_Norm_toTensor = A.Compose([\n",
        "                            A.Resize(CFG['IMG_SIZE'],CFG['IMG_SIZE']),\n",
        "                            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=False, p=1.0),\n",
        "                            ToTensorV2()\n",
        "                            ])\n",
        "augmentedData = A.Compose([\n",
        "                            A.Resize(CFG['IMG_SIZE'],CFG['IMG_SIZE']),\n",
        "                            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=False, p=1.0),\n",
        "                            A.OneOf([\n",
        "                                    A.HorizontalFlip(p=0.5),\n",
        "                                    A.RandomRotate90(p=0.5),\n",
        "                                    A.VerticalFlip(p=0.5)\n",
        "                                    ], p=1),\n",
        "                            A.OneOf([\n",
        "                                    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=0, p=1.0)\n",
        "                                    ], p=1),\n",
        "                            ToTensorV2()\n",
        "                            ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6Cz49qmn855"
      },
      "outputs": [],
      "source": [
        "# 1. 기존의 이미지 -> tensor\n",
        "train_dataset = CustomDataset(train_df['path'].values, train_label_vec, A_Norm_toTensor)\n",
        "# 2. Data Augmentation\n",
        "train_augmented_1 = CustomDataset(train_df['path'].values, train_label_vec, augmentedData)\n",
        "train_augmented_2 = CustomDataset(train_df['path'].values, train_label_vec, augmentedData)\n",
        "train_concat = torch.utils.data.ConcatDataset([train_dataset, train_augmented_1, train_augmented_2])\n",
        "# 3. 1+2(concatenate) -> DataLoader\n",
        "train_loader = DataLoader(train_concat, batch_size = CFG['BATCH_SIZE'], shuffle=True, num_workers=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ez_9yKYrTd2a"
      },
      "outputs": [],
      "source": [
        "val_dataset = CustomDataset(val_df['path'].values, val_label_vec, A_Norm_toTensor)\n",
        "val_augmented_1 = CustomDataset(train_df['path'].values, train_label_vec, augmentedData)\n",
        "val_augmented_2 = CustomDataset(train_df['path'].values, train_label_vec, augmentedData)\n",
        "val_concat = torch.utils.data.ConcatDataset([val_dataset, val_augmented_1, val_augmented_2])\n",
        "val_loader = DataLoader(train_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=True, num_workers=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ueR8ZqMAHJn"
      },
      "outputs": [],
      "source": [
        "# Feature Extraction(resnext101_32x8d) + FFNN(2layer)\n",
        "class BaseModel(nn.Module):\n",
        "    def __init__(self, gene_size=CFG['label_size'], fc_dropout_prob=0.3):\n",
        "        super(BaseModel, self).__init__()\n",
        "\n",
        "        # Pretrained ResNet (여기서는 ResNext101)\n",
        "        self.backbone = models.resnext101_32x8d(pretrained=True)\n",
        "\n",
        "        # 추가적인 fully connected 레이어 및 dropout\n",
        "        self.fc1 = nn.Linear(1000, 512)  # 추가 레이어\n",
        "        self.fc_dropout = nn.Dropout(p=fc_dropout_prob)\n",
        "        self.fc2 = nn.Linear(512, gene_size)  # 최종 회귀층\n",
        "\n",
        "    def forward(self, x):\n",
        "        # ResNet backbone을 통해 feature 추출\n",
        "        x = self.backbone(x)\n",
        "        x = self.fc_dropout(x)\n",
        "\n",
        "        # 추가 FC 레이어 적용\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc_dropout(x)\n",
        "\n",
        "        # 최종 출력 레이어\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pCHzME_yoDLp"
      },
      "outputs": [],
      "source": [
        "def train(model, optimizer, train_loader, val_loader, scheduler, device, epochs=CFG['EPOCHS']):\n",
        "    model.to(device)\n",
        "    criterion = nn.MSELoss().to(device)\n",
        "\n",
        "    best_loss = 99999999\n",
        "    best_model = None\n",
        "\n",
        "    for epoch in range(1, epochs+1):\n",
        "        model.train()\n",
        "        train_loss = []\n",
        "        for imgs, labels in tqdm(iter(train_loader)):\n",
        "            imgs = imgs.float().to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            output = model(imgs)\n",
        "            loss = criterion(output, labels)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss.append(loss.item())\n",
        "\n",
        "        _val_loss = validation(model, criterion, val_loader, device)\n",
        "        _train_loss = np.mean(train_loss)\n",
        "        print(f'Epoch [{epoch}], Train Loss : [{_train_loss:.5f}] Val Loss : [{_val_loss:.5f}]')\n",
        "\n",
        "        if scheduler is not None:\n",
        "            scheduler.step(_val_loss)\n",
        "\n",
        "        if best_loss > _val_loss:\n",
        "            best_loss = _val_loss\n",
        "            best_model = model\n",
        "\n",
        "    return best_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fdu1dF7-oErQ"
      },
      "outputs": [],
      "source": [
        "def validation(model, criterion, val_loader, device):\n",
        "    model.eval()\n",
        "    val_loss = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in tqdm(iter(val_loader)):\n",
        "            imgs = imgs.float().to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            pred = model(imgs)\n",
        "\n",
        "            loss = criterion(pred, labels)\n",
        "\n",
        "            val_loss.append(loss.item())\n",
        "\n",
        "        _val_loss = np.mean(val_loss)\n",
        "\n",
        "    return _val_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtD7gAvQoHeu",
        "outputId": "3442c8fd-9c6a-4f75-ab80-ed0ebc50aaa2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnext101_32x8d-8ba56ff5.pth\" to /root/.cache/torch/hub/checkpoints/resnext101_32x8d-8ba56ff5.pth\n",
            "100%|██████████| 340M/340M [00:02<00:00, 131MB/s]\n",
            "100%|██████████| 350/350 [1:24:01<00:00, 14.40s/it]\n",
            "100%|██████████| 175/175 [01:53<00:00,  1.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1], Train Loss : [0.04645] Val Loss : [0.04605]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 350/350 [10:32<00:00,  1.81s/it]\n",
            "100%|██████████| 175/175 [01:51<00:00,  1.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2], Train Loss : [0.04655] Val Loss : [0.04548]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 350/350 [10:25<00:00,  1.79s/it]\n",
            "100%|██████████| 175/175 [01:49<00:00,  1.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3], Train Loss : [0.04645] Val Loss : [0.04914]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 350/350 [10:18<00:00,  1.77s/it]\n",
            "100%|██████████| 175/175 [01:49<00:00,  1.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4], Train Loss : [0.04641] Val Loss : [0.12749]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 350/350 [10:18<00:00,  1.77s/it]\n",
            "100%|██████████| 175/175 [01:50<00:00,  1.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5], Train Loss : [0.04633] Val Loss : [0.04618]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 350/350 [10:23<00:00,  1.78s/it]\n",
            "100%|██████████| 175/175 [01:50<00:00,  1.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6], Train Loss : [0.04627] Val Loss : [0.04644]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 350/350 [10:23<00:00,  1.78s/it]\n",
            "100%|██████████| 175/175 [01:49<00:00,  1.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7], Train Loss : [0.04603] Val Loss : [0.04528]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 350/350 [10:25<00:00,  1.79s/it]\n",
            "100%|██████████| 175/175 [01:51<00:00,  1.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8], Train Loss : [0.04594] Val Loss : [0.04511]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 350/350 [10:20<00:00,  1.77s/it]\n",
            "100%|██████████| 175/175 [01:49<00:00,  1.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9], Train Loss : [0.04584] Val Loss : [0.21387]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 350/350 [10:20<00:00,  1.77s/it]\n",
            "100%|██████████| 175/175 [01:49<00:00,  1.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10], Train Loss : [0.04603] Val Loss : [0.04531]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 350/350 [10:22<00:00,  1.78s/it]\n",
            "100%|██████████| 175/175 [01:49<00:00,  1.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [11], Train Loss : [0.04592] Val Loss : [0.04554]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 350/350 [10:20<00:00,  1.77s/it]\n",
            "100%|██████████| 175/175 [01:49<00:00,  1.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [12], Train Loss : [0.04568] Val Loss : [0.04565]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 350/350 [10:20<00:00,  1.77s/it]\n",
            "100%|██████████| 175/175 [01:48<00:00,  1.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [13], Train Loss : [0.04561] Val Loss : [0.04508]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 350/350 [10:18<00:00,  1.77s/it]\n",
            "100%|██████████| 175/175 [01:48<00:00,  1.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [14], Train Loss : [0.04555] Val Loss : [0.04469]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 350/350 [10:19<00:00,  1.77s/it]\n",
            "100%|██████████| 175/175 [01:48<00:00,  1.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [15], Train Loss : [0.04550] Val Loss : [0.04562]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 350/350 [10:19<00:00,  1.77s/it]\n",
            "100%|██████████| 175/175 [01:49<00:00,  1.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [16], Train Loss : [0.04547] Val Loss : [0.04508]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 350/350 [10:21<00:00,  1.78s/it]\n",
            "100%|██████████| 175/175 [01:49<00:00,  1.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [17], Train Loss : [0.04547] Val Loss : [0.04582]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 350/350 [10:20<00:00,  1.77s/it]\n",
            "100%|██████████| 175/175 [01:49<00:00,  1.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [18], Train Loss : [0.04535] Val Loss : [0.04483]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 350/350 [10:23<00:00,  1.78s/it]\n",
            "100%|██████████| 175/175 [01:49<00:00,  1.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [19], Train Loss : [0.04533] Val Loss : [0.04515]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 350/350 [10:24<00:00,  1.78s/it]\n",
            "100%|██████████| 175/175 [01:50<00:00,  1.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [20], Train Loss : [0.04530] Val Loss : [0.04497]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "model = BaseModel()\n",
        "# Load sota model\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/resnext_2drop.pth'))\n",
        "model.eval()\n",
        "optimizer = torch.optim.Adam(params = model.parameters(), lr = CFG[\"LEARNING_RATE\"])\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2, threshold_mode='abs', min_lr=1e-8, verbose=True)\n",
        "\n",
        "infer_model = train(model, optimizer, train_loader, val_loader, scheduler, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "suELxozSoJh0",
        "outputId": "7bb441e4-3735-4586-c22b-ac1dc3577ee4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 72/72 [00:41<00:00,  1.75it/s]\n"
          ]
        }
      ],
      "source": [
        "test = pd.read_csv('/content/drive/MyDrive/open/test.csv')\n",
        "updated_paths = transform_test_path(test)\n",
        "\n",
        "test_dataset = CustomDataset(updated_paths, None, A_Norm_toTensor)\n",
        "test_loader = DataLoader(test_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=0)\n",
        "\n",
        "def inference(model, test_loader, device):\n",
        "    model.eval()\n",
        "    preds = []\n",
        "    with torch.no_grad():\n",
        "        for imgs in tqdm(test_loader):\n",
        "            imgs = imgs.to(device).float()\n",
        "            pred = model(imgs)\n",
        "\n",
        "            preds.append(pred.detach().cpu())\n",
        "\n",
        "    preds = torch.cat(preds).numpy()\n",
        "\n",
        "    return preds\n",
        "\n",
        "preds = inference(infer_model, test_loader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ek_JK_rBL1O3",
        "outputId": "41177fcc-2b38-4000-af9f-f7167768a560"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 72/72 [00:54<00:00,  1.33it/s]\n"
          ]
        }
      ],
      "source": [
        "test_dataset_augmented = CustomDataset(updated_paths, None, augmentedData)\n",
        "test_loader_augmented = DataLoader(test_dataset_augmented, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=0)\n",
        "\n",
        "\n",
        "preds_augmented = inference(infer_model, test_loader_augmented, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jsk9_WweeueG",
        "outputId": "a9faac4c-e34a-4290-b162-980801634a8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 72/72 [00:56<00:00,  1.28it/s]\n"
          ]
        }
      ],
      "source": [
        "test_dataset_augmented_1 = CustomDataset(updated_paths, None, augmentedData)\n",
        "test_loader_augmented_1 = DataLoader(test_dataset_augmented, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=0)\n",
        "\n",
        "\n",
        "preds_augmented_1 = inference(infer_model, test_loader_augmented, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JnfL0BblM988"
      },
      "outputs": [],
      "source": [
        "# test 이미지에 대한 augmentation(한 이미지를 여러 방향에서 바라본 후), 3개의 이미지에 대한 평균 값 제출\n",
        "average_preds = (preds + preds_augmented + preds_augmented_1) / 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CPVZDRHPoLZa"
      },
      "outputs": [],
      "source": [
        "submit = pd.read_csv('/content/drive/MyDrive/open/sample_submission.csv')\n",
        "submit.iloc[:, 1:] = np.array(average_preds).astype(np.float32)\n",
        "submit.to_csv('./baseline_submit.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyNrzCYF5Eb2/BiG439DuNvd",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}